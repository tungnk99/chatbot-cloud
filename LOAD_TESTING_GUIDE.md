# ğŸ¦— Load Testing vá»›i Locust - Chá»©ng Minh Auto-scaling

## ğŸ“Œ Má»¤C Lá»¤C

1. [Giá»›i Thiá»‡u](#giá»›i-thiá»‡u)
2. [Quick Start](#quick-start)
3. [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
4. [Cháº¡y Tests](#cháº¡y-tests)
5. [Thu Tháº­p Evidence](#thu-tháº­p-evidence)
6. [PhÃ¢n TÃ­ch Káº¿t Quáº£](#phÃ¢n-tÃ­ch-káº¿t-quáº£)
7. [Demo Script](#demo-script)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ GIá»šI THIá»†U

Guide nÃ y hÆ°á»›ng dáº«n sá»­ dá»¥ng **Locust** Ä‘á»ƒ:
- âœ… Load test há»‡ thá»‘ng vá»›i giao diá»‡n web trá»±c quan
- âœ… Chá»©ng minh kháº£ nÄƒng **auto-scaling** cá»§a Cloud Run
- âœ… Thu tháº­p evidence (metrics, screenshots, reports)
- âœ… Demo live cho presentation

### Táº¡i Sao DÃ¹ng Locust?

| Æ¯u Äiá»ƒm | Chi Tiáº¿t |
|---------|----------|
| ğŸ¨ **Giao diá»‡n Ä‘áº¹p** | Web UI real-time vá»›i charts tá»± Ä‘á»™ng |
| ğŸ“Š **Graphs tÃ­ch há»£p** | Response time, RPS, failures |
| ğŸ›ï¸ **Dynamic control** | Äiá»u chá»‰nh sá»‘ users on-the-fly |
| ğŸ“„ **HTML reports** | Export reports Ä‘áº¹p vá»›i graphs |
| ğŸ‘€ **Live monitoring** | Xem metrics real-time |
| ğŸ“¸ **Demo friendly** | HoÃ n háº£o cho presentation |

### Cáº¥u HÃ¬nh Auto-scaling

```hcl
# Cloud Run Configuration
min_instances = 0  # Scale-to-zero
max_instances = 10
cpu = 1 vCPU
memory = 512Mi
```

---

## ğŸš€ QUICK START

### 3 BÆ°á»›c Nhanh

```bash
# 1. CÃ i Ä‘áº·t
pip install -r tests/load/requirements.txt

# 2. Cháº¡y Locust
./run-locust-interactive.sh

# 3. Má»Ÿ browser
http://localhost:8089
```

### 2 CÃ¡ch Cháº¡y Tests

| CÃ¡ch | Thá»i Gian | Sá»­ Dá»¥ng |
|------|-----------|---------|
| **Interactive** | 15-20 phÃºt | â­ Demo live, presentation |
| **Automated** | 20-25 phÃºt | Thu tháº­p evidence Ä‘áº§y Ä‘á»§ |

---

## ğŸ“¦ CÃ€I Äáº¶T

### Prerequisites

```bash
# Python 3.8+
python3 --version

# Pip
pip --version

# Google Cloud CLI (optional, cho metrics)
gcloud --version
```

### Install Dependencies

```bash
cd /home/tungnk/Desktop/Masters-HUST/Cloud\ Computing/BTL/chatbot-cloud

# Install tá»« requirements
pip install -r tests/load/requirements.txt

# Hoáº·c install trá»±c tiáº¿p
pip install locust==2.32.4 httpx==0.28.1
```

### Verify Installation

```bash
locust --version
# Output: locust 2.32.4
```

---

## ğŸ¦— CHáº Y TESTS

### CÃCH 1: Interactive Mode (Recommended)

#### Khá»Ÿi Äá»™ng Locust Web UI

```bash
# Set service URL (Ä‘Ã£ cÃ³ sáºµn trong script)
export CHATBOT_URL="https://chatbot-api-hbfjjbwmsa-as.a.run.app"

# Cháº¡y script
./run-locust-interactive.sh
```

Output:
```
ğŸ¦— Locust Interactive Load Testing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target URL:  https://chatbot-api-hbfjjbwmsa-as.a.run.app
Web UI URL:  http://localhost:8089

Starting Locust...
```

#### Má»Ÿ Web UI

```bash
# Tá»± Ä‘á»™ng má»Ÿ trong browser
xdg-open http://localhost:8089

# Hoáº·c má»Ÿ manual
firefox http://localhost:8089
```

#### Chuáº©n Bá»‹ 2 Tabs

**Tab 1**: Locust UI
- http://localhost:8089

**Tab 2**: GCP Console Metrics
- https://console.cloud.google.com/run/detail/asia-southeast1/chatbot-api/metrics

#### Ká»‹ch Báº£n Test

##### Test 1: Baseline (1-2 phÃºt)
```
Purpose: Wake up service, verify connectivity
Settings:
  - Number of users: 5
  - Spawn rate: 1 user/second
  - Click "Start swarming"

Expected:
  - GCP Console: Instances 0 â†’ 1
  - Locust: Success rate >95%
  - Response time: <3s
```

##### Test 2: Light Load (2-3 phÃºt)
```
Purpose: Light traffic, basic scaling
Settings:
  - Stop previous test
  - Number of users: 10
  - Spawn rate: 2 users/second
  - Start swarming

Expected:
  - GCP Console: 1-2 instances
  - Locust: 3-5 RPS
  - Success rate: >95%

ğŸ“¸ CHá»¤P SCREENSHOTS:
  - Locust Statistics table
  - Locust Charts tab
  - GCP Instance count
```

##### Test 3: Medium Load (3-4 phÃºt)
```
Purpose: Moderate scaling
Settings:
  - Stop test
  - Wait 1 minute (scale-down)
  - Number of users: 50
  - Spawn rate: 5 users/second
  - Start swarming

Expected:
  - GCP Console: 3-5 instances
  - Locust: 15-25 RPS
  - Success rate: >90%
  - Response time: <5s

ğŸ“¸ CHá»¤P SCREENSHOTS:
  - GCP Instance count tÄƒng
  - Locust Charts showing load increase
```

##### Test 4: Heavy Load (3-4 phÃºt)
```
Purpose: Near-max capacity
Settings:
  - Stop test
  - Wait 1 minute
  - Number of users: 100
  - Spawn rate: 10 users/second
  - Start swarming

Expected:
  - GCP Console: 7-10 instances (max)
  - Locust: 30-50 RPS
  - Success rate: >85%
  - Response time: <8s

ğŸ“¸ CHá»¤P SCREENSHOTS:
  - GCP Instance count at max
  - Locust performance under load
```

##### Test 5: Spike Test (2-3 phÃºt)
```
Purpose: Rapid scaling test
Settings:
  - Stop test
  - Number of users: 200
  - Spawn rate: 50 users/second (RAPID!)
  - Start swarming

Expected:
  - GCP Console: Rapid scale to 8-10 instances
  - Locust: 40-70 RPS
  - Success rate: >80%
  - Some latency increase acceptable

ğŸ“¸ CHá»¤P SCREENSHOTS:
  - Rapid scaling in GCP
  - Spike handling in Locust
```

##### Test 6: Scale-down (5-10 phÃºt)
```
Purpose: Verify auto scale-down
Settings:
  - Stop all tests
  - Watch GCP Console

Expected:
  - GCP Console: Instances gradually decrease
  - After 5-10 minutes: Back to 0 instances
  - Demonstrates scale-to-zero

ğŸ“¸ CHá»¤P SCREENSHOTS:
  - Scale-down progress
  - Final state: 0 instances
```

#### Export Reports

Sau má»—i test phase:
1. Locust UI â†’ Tab **"Download Data"**
2. Click **"Download Report"**
3. Save HTML file: `report-light.html`, `report-medium.html`, etc.

#### Stop Locust

```bash
# Press Ctrl+C trong terminal
^C
```

---

### CÃCH 2: Automated Mode

#### Cháº¡y Táº¥t Cáº£ Tests Tá»± Äá»™ng

```bash
# Cháº¡y script automated
./run-locust-tests.sh
```

Script sáº½:
- âœ… Cháº¡y 4 test profiles (light, medium, heavy, spike)
- âœ… Thu tháº­p GCP metrics sau má»—i test
- âœ… Wait cooldown giá»¯a cÃ¡c tests
- âœ… Táº¡o HTML reports tá»± Ä‘á»™ng
- âœ… Export metrics JSON
- âœ… Generate summary README

**Thá»i gian**: ~20-25 phÃºt

**Output**: `evidence/locust-YYYYMMDD_HHMMSS/`

#### Xem Káº¿t Quáº£

```bash
# Navigate to evidence folder
cd evidence/locust-*/

# List all reports
ls -lh locust-reports/

# Open HTML reports
xdg-open locust-reports/01-light.html
xdg-open locust-reports/02-medium.html
xdg-open locust-reports/03-heavy.html
xdg-open locust-reports/04-spike.html

# View metrics
ls -lh metrics/

# Read summary
cat README.md
```

---

## ğŸ“Š THU THáº¬P EVIDENCE

### 1. Locust Reports

#### HTML Reports
Má»—i report bao gá»“m:
- **Statistics Table**: RPS, response times, success rate
- **Charts**: Response time distribution, RPS over time
- **Failures**: Error details (náº¿u cÃ³)
- **Download Data**: Export CSV

#### CSV Files
- `*_stats.csv`: Statistics chi tiáº¿t
- `*_failures.csv`: Failures log
- `*_stats_history.csv`: Timeline data

### 2. Screenshots tá»« Locust UI

#### Tab Statistics
- [ ] Request count vÃ  success rate
- [ ] Median response time
- [ ] 95th percentile latency
- [ ] Requests per second
- [ ] Failures count

#### Tab Charts
- [ ] Total Requests per Second (timeline)
- [ ] Response Times (timeline)
- [ ] Number of Users (ramp-up pattern)

#### Tab Failures (náº¿u cÃ³)
- [ ] Error types vÃ  counts
- [ ] Failed requests details

### 3. Screenshots tá»« GCP Console

#### Metrics Tab
Navigate to: **Cloud Run â†’ chatbot-api â†’ METRICS**

Chá»¥p screenshots:
- [ ] **Container instance count** (graph chÃ­nh - toÃ n bá»™ timeline)
- [ ] Instance count táº¡i má»—i load level (0â†’1â†’5â†’10â†’0)
- [ ] **Request count** over time
- [ ] **Request latency** percentiles (P50, P95, P99)
- [ ] **CPU utilization**
- [ ] **Memory utilization**

#### Logs Tab
Navigate to: **Cloud Run â†’ chatbot-api â†’ LOGS**

Filter logs:
```
resource.type="cloud_run_revision"
"Starting" OR "Shutting down"
```

Chá»¥p screenshots:
- [ ] Instance start events
- [ ] Instance stop events
- [ ] Scaling logs timeline

#### Service Details
Navigate to: **Cloud Run â†’ chatbot-api**

Chá»¥p screenshot:
- [ ] Service configuration showing:
  - Min instances: 0
  - Max instances: 10
  - CPU: 1 vCPU
  - Memory: 512Mi

### 4. Export Metrics tá»« GCP CLI

```bash
# Create evidence folder
mkdir -p evidence/manual-$(date +%Y%m%d_%H%M%S)
cd evidence/manual-*

# Instance count metrics
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/container/instance_count" AND resource.labels.service_name="chatbot-api"' \
  --format=json \
  --freshness=1h \
  > instance-count.json

# Request count
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/request_count" AND resource.labels.service_name="chatbot-api"' \
  --format=json \
  --freshness=1h \
  > request-count.json

# Request latency
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/request_latencies" AND resource.labels.service_name="chatbot-api"' \
  --format=json \
  --freshness=1h \
  > request-latency.json

# CPU utilization
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/container/cpu/utilizations" AND resource.labels.service_name="chatbot-api"' \
  --format=json \
  --freshness=1h \
  > cpu-utilization.json

# Scaling logs
gcloud logging read \
  'resource.type="cloud_run_revision" 
   AND resource.labels.service_name="chatbot-api"
   AND ("Starting" OR "Shutting down")' \
  --limit=200 \
  --format=json \
  --freshness=1h \
  > scaling-logs.json
```

### 5. Evidence Checklist

#### Test Results
- [ ] Locust HTML reports (4 files: light, medium, heavy, spike)
- [ ] CSV statistics files
- [ ] CSV failures files (náº¿u cÃ³)
- [ ] Test logs

#### Screenshots - Locust
- [ ] Statistics table cho má»—i test
- [ ] Charts: Response time over time
- [ ] Charts: Total RPS over time
- [ ] Charts: Number of users ramp-up
- [ ] Download data section

#### Screenshots - GCP Console
- [ ] Instance count graph (full timeline)
- [ ] Instance count at baseline (0)
- [ ] Instance count at light load (1-2)
- [ ] Instance count at medium load (3-5)
- [ ] Instance count at heavy load (7-10)
- [ ] Instance count after scale-down (0)
- [ ] Request latency percentiles
- [ ] Service configuration

#### Metrics Data
- [ ] instance-count.json
- [ ] request-count.json
- [ ] request-latency.json
- [ ] cpu-utilization.json
- [ ] scaling-logs.json

---

## ğŸ“ˆ PHÃ‚N TÃCH Káº¾T QUáº¢

### Reading Locust HTML Reports

#### 1. Statistics Section

| Metric | Good | Acceptable | Poor |
|--------|------|------------|------|
| **Success Rate** | >95% | >85% | <85% |
| **Median Response** | <3s | <5s | >5s |
| **95th Percentile** | <8s | <12s | >12s |
| **Requests/sec** | Increasing | Stable | Decreasing |

#### 2. Charts Analysis

**Response Time Chart**:
- âœ… Stable horizontal line = good performance
- âš ï¸ Gradual increase = approaching limits
- âŒ Spikes during scaling = normal, should stabilize

**Total RPS Chart**:
- âœ… Increases with users = good scaling
- âš ï¸ Plateaus = hitting capacity
- âŒ Decreases = system overload

**Number of Users Chart**:
- Verify ramp-up pattern matches spawn rate
- Smooth curve = healthy spawn rate

### Correlating vá»›i GCP Metrics

#### Timeline Correlation

| Time | Locust Users | RPS | GCP Instances | Observation |
|------|--------------|-----|---------------|-------------|
| 0:00 | 0 | 0 | 0 | Baseline: scale-to-zero |
| 0:30 | 5 | 2 | 1 | Wake up from 0 |
| 2:00 | 10 | 5 | 1-2 | Light load |
| 5:00 | 50 | 20 | 3-5 | Medium scaling |
| 8:00 | 100 | 45 | 7-10 | Heavy load |
| 11:00 | 200 | 60 | 10 | Max instances |
| 13:00 | 0 | 0 | 5 | Scale-down started |
| 18:00 | 0 | 0 | 0 | Back to zero |

### Expected Results

#### Test Performance

| Test | Users | Total Requests | Success Rate | Avg Latency | P95 Latency | RPS | Instances |
|------|-------|----------------|--------------|-------------|-------------|-----|-----------|
| Light | 10 | ~100 | >95% | <3s | <5s | 3-5 | 1-2 |
| Medium | 50 | ~1000 | >90% | <4s | <8s | 15-25 | 3-5 |
| Heavy | 100 | ~2500 | >85% | <6s | <12s | 30-50 | 7-10 |
| Spike | 200 | ~1500 | >80% | <8s | <15s | 40-70 | 8-10 |

#### Auto-scaling Evidence

âœ… **Scale-up Demonstrated**:
- Instance count tÄƒng tá»« 0 â†’ 1 â†’ 3 â†’ 5 â†’ 10
- TÆ°Æ¡ng á»©ng vá»›i load tÄƒng
- Response time váº«n acceptable

âœ… **Performance Under Load**:
- Success rate duy trÃ¬ >85%
- Latency khÃ´ng tÄƒng quÃ¡ nhiá»u
- System handle Ä‘Æ°á»£c traffic

âœ… **Elasticity**:
- Instances scale nhanh khi load tÄƒng Ä‘á»™t ngá»™t
- KhÃ´ng cÃ³ downtime during scaling

âœ… **Scale-down Demonstrated**:
- Instance count giáº£m sau khi load giáº£m
- Return vá» 0 (min_instances)
- Cost optimization working

âœ… **Scale-to-Zero**:
- Service start tá»« 0 instances
- Return vá» 0 khi idle
- Tiáº¿t kiá»‡m chi phÃ­

---

## ğŸ¬ DEMO SCRIPT (CHO PRESENTATION)

### Preparation (5 phÃºt trÆ°á»›c)

```bash
# 1. Verify service Ä‘ang idle
gcloud run services describe chatbot-api --region=asia-southeast1 | grep instance

# 2. Start Locust
./run-locust-interactive.sh

# 3. Open browsers
firefox http://localhost:8089 &
firefox https://console.cloud.google.com/run/detail/asia-southeast1/chatbot-api/metrics &

# 4. Arrange windows side-by-side
```

### Live Demo Timeline (10-12 phÃºt)

#### 00:00 - 01:00 | Giá»›i Thiá»‡u
```
ğŸ¤ "HÃ´m nay tÃ´i sáº½ demo kháº£ nÄƒng auto-scaling cá»§a há»‡ thá»‘ng"

Show screens:
- Locust UI
- GCP Console: 0 instances (scale-to-zero)

ğŸ¤ "Hiá»‡n táº¡i service Ä‘ang á»Ÿ 0 instances Ä‘á»ƒ tiáº¿t kiá»‡m chi phÃ­"
```

#### 01:00 - 03:00 | Baseline Test
```
Locust UI:
- Number of users: 5
- Spawn rate: 1
- Click "Start swarming"

ğŸ¤ "Khi cÃ³ traffic, Cloud Run tá»± Ä‘á»™ng táº¡o instance Ä‘áº§u tiÃªn"

Show GCP Console:
- Instance count: 0 â†’ 1
- Request count tÄƒng

ğŸ¤ "ÄÃ¢y lÃ  scale-up tá»« zero. Service ready trong vÃ i giÃ¢y"
```

#### 03:00 - 06:00 | Medium Load
```
Locust UI:
- Stop test
- Number of users: 50
- Spawn rate: 5
- Start swarming

ğŸ¤ "TÄƒng lÃªn 50 concurrent users"

Show GCP Console:
- Instance count: 1 â†’ 3 â†’ 5
- Graphs tÄƒng

Show Locust Charts:
- RPS tÄƒng
- Response time stable

ğŸ¤ "Há»‡ thá»‘ng tá»± Ä‘á»™ng scale lÃªn 5 instances"
ğŸ¤ "Response time váº«n á»•n Ä‘á»‹nh nhá» auto-scaling"
```

#### 06:00 - 09:00 | Heavy Load
```
Locust UI:
- Stop, wait 30s
- Number of users: 100
- Spawn rate: 10
- Start swarming

ğŸ¤ "TÄƒng lÃªn 100 users Ä‘á»ƒ test near-max capacity"

Show GCP Console:
- Instance count: 5 â†’ 8 â†’ 10 (max)

Show Locust:
- Higher RPS
- Still acceptable response times

ğŸ¤ "Äáº¡t max 10 instances nhÆ° Ä‘Ã£ config"
ğŸ¤ "Success rate váº«n >85%, system handle tá»‘t"
```

#### 09:00 - 12:00 | Scale-down
```
Locust UI:
- Stop test

ğŸ¤ "BÃ¢y giá» tÃ´i stop test Ä‘á»ƒ xem scale-down"

Watch GCP Console:
- Instance count: 10 â†’ 7 â†’ 5 â†’ 3 â†’ 1 â†’ 0

ğŸ¤ "Khi khÃ´ng cÃ²n traffic, instances tá»± Ä‘á»™ng giáº£m"
ğŸ¤ "Sau vÃ i phÃºt, vá» láº¡i 0 instances"
ğŸ¤ "ÄÃ¢y lÃ  cost optimization - chá»‰ tráº£ tiá»n khi cÃ³ traffic"
```

### Key Messages cho Demo

```
âœ… "Scale-to-zero: Start tá»« 0, tiáº¿t kiá»‡m chi phÃ­ khi idle"

âœ… "Auto scale-up: Tá»± Ä‘á»™ng táº¡o instances khi cÃ³ traffic"

âœ… "Proportional scaling: Instances tÄƒng theo load (1â†’5â†’10)"

âœ… "Performance maintained: Response time stable nhá» scaling"

âœ… "Elasticity: Rapid response to demand changes"

âœ… "Auto scale-down: Giáº£m instances khi idle, optimize costs"

âœ… "Cloud native benefits: KhÃ´ng cáº§n manual intervention"
```

### Talking Points

**Scale-to-zero**:
> "Khi khÃ´ng cÃ³ traffic, service á»Ÿ 0 instances. ChÃºng ta khÃ´ng máº¥t tiá»n cho resources khÃ´ng dÃ¹ng."

**Scale-up**:
> "Khi cÃ³ request Ä‘áº§u tiÃªn, Cloud Run tá»± Ä‘á»™ng táº¡o instance. KhÃ´ng cáº§n config thÃªm gÃ¬."

**Proportional**:
> "Load tÄƒng, instances tÄƒng. Tá»« 1 lÃªn 5 lÃªn 10. HoÃ n toÃ n tá»± Ä‘á»™ng."

**Performance**:
> "NhÃ¬n vÃ o graph Locust, response time váº«n á»•n Ä‘á»‹nh dÃ¹ load tÄƒng. ÄÃ³ lÃ  nhá» auto-scaling."

**Cost**:
> "Sau khi test xong, instances tá»± Ä‘á»™ng giáº£m vá» 0. ÄÃ¢y lÃ  optimization - chá»‰ tráº£ cho nhá»¯ng gÃ¬ dÃ¹ng."

---

## ğŸ› TROUBLESHOOTING

### Issue 1: Port 8089 Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng

```bash
# Check process
lsof -i :8089

# Kill old process
pkill -f locust

# Hoáº·c dÃ¹ng port khÃ¡c
LOCUST_PORT=8090 ./run-locust-interactive.sh
```

### Issue 2: Locust khÃ´ng start

```bash
# Check installation
locust --version

# Reinstall
pip uninstall locust
pip install locust==2.32.4

# Check Python version
python3 --version  # Need 3.8+
```

### Issue 3: High failure rate trong tests

**NguyÃªn nhÃ¢n**:
- Cold start (service Ä‘ang á»Ÿ 0 instances)
- Rate limiting
- Service errors

**Giáº£i phÃ¡p**:
```bash
# 1. Warm up service trÆ°á»›c
# Start vá»›i baseline test (5 users) trÆ°á»›c khi heavy test

# 2. Giáº£m spawn rate
# Thay vÃ¬ 50 users/s, dÃ¹ng 10 users/s

# 3. Check service logs
./view-logs.sh chatbot

# 4. Verify service health
curl https://chatbot-api-hbfjjbwmsa-as.a.run.app/health
```

### Issue 4: KhÃ´ng tháº¥y scaling trong GCP Console

**Check configuration**:
```bash
# Verify max_instances
cd infrastructure/terraform
terraform show | grep max_instance

# Should show: max_instance_count = 10
```

**Check current state**:
```bash
# Get current instances
gcloud run services describe chatbot-api \
  --region=asia-southeast1 \
  --format='value(status.traffic[0].latestRevision)'

# Check quotas
gcloud compute project-info describe --project=$(gcloud config get-value project)
```

**Wait for metrics**:
- Metrics cÃ³ thá»ƒ delay 2-5 phÃºt
- Refresh GCP Console (F5)
- Wait vÃ  check láº¡i

### Issue 5: Service timeout

```bash
# Check timeout setting
gcloud run services describe chatbot-api \
  --region=asia-southeast1 \
  --format='value(spec.template.spec.timeoutSeconds)'

# Should be: 300s

# Check logs for actual errors
gcloud logging read \
  'resource.type="cloud_run_revision" 
   AND resource.labels.service_name="chatbot-api"
   AND severity>=ERROR' \
  --limit=20
```

### Issue 6: Cannot access GCP metrics

```bash
# Login to gcloud
gcloud auth login

# Set project
gcloud config set project YOUR_PROJECT_ID

# Test access
gcloud monitoring time-series list --limit=1
```

---

## ğŸ“š REFERENCE

### Test Profiles Summary

| Profile | Users | Spawn Rate | Duration | Expected |
|---------|-------|------------|----------|----------|
| Baseline | 5 | 1/s | 1-2m | Wake up service |
| Light | 10 | 2/s | 2-3m | 1-2 instances |
| Medium | 50 | 5/s | 3-4m | 3-5 instances |
| Heavy | 100 | 10/s | 3-4m | 7-10 instances |
| Spike | 200 | 50/s | 2-3m | Rapid to max |

### Scripts Quick Reference

```bash
# Interactive mode (recommended)
./run-locust-interactive.sh

# Automated mode
./run-locust-tests.sh

# Manual Locust command
CHATBOT_URL="<URL>" locust \
  -f tests/load/locustfile.py \
  --host="<URL>" \
  --users=50 \
  --spawn-rate=5 \
  --run-time=3m \
  --headless \
  --html=report.html

# Check service
gcloud run services describe chatbot-api --region=asia-southeast1

# View logs
gcloud logging read 'resource.type="cloud_run_revision"' --limit=20

# Get instance count
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/container/instance_count"' \
  --format=json --freshness=5m
```

### Files Structure

```
chatbot-cloud/
â”œâ”€â”€ run-locust-interactive.sh    # â­ Interactive mode
â”œâ”€â”€ run-locust-tests.sh          # Automated mode
â”œâ”€â”€ LOAD_TESTING_GUIDE.md        # â­ This file
â”œâ”€â”€ tests/load/
â”‚   â”œâ”€â”€ locustfile.py           # Test scenarios
â”‚   â”œâ”€â”€ requirements.txt        # Dependencies
â”‚   â””â”€â”€ README.md               # Load tests overview
â””â”€â”€ evidence/                    # Test results output
    â””â”€â”€ locust-YYYYMMDD_HHMMSS/
        â”œâ”€â”€ locust-reports/     # HTML reports
        â”œâ”€â”€ metrics/            # GCP metrics JSON
        â””â”€â”€ README.md           # Test summary
```

### Important URLs

- **Locust Docs**: https://docs.locust.io/
- **GCP Console**: https://console.cloud.google.com/run
- **Cloud Run Docs**: https://cloud.google.com/run/docs/configuring/max-instances

---

## âœ… CHECKLIST CUá»I CÃ™NG

### TrÆ°á»›c Khi Demo

- [ ] Install dependencies: `pip install -r tests/load/requirements.txt`
- [ ] Verify service URL trong script
- [ ] Test cháº¡y Locust: `./run-locust-interactive.sh`
- [ ] Verify GCP Console access
- [ ] Prepare 2 browser tabs (Locust + GCP)
- [ ] (Optional) Screen recording tool

### Trong Demo

- [ ] Cháº¡y baseline test
- [ ] Chá»¥p screenshot sau má»—i test
- [ ] Export Locust HTML reports
- [ ] Monitor GCP Console real-time
- [ ] Document observations

### Sau Demo

- [ ] Thu tháº­p táº¥t cáº£ screenshots
- [ ] Export GCP metrics JSON
- [ ] Organize evidence folder
- [ ] Táº¡o summary report
- [ ] Review findings

---

## ğŸ‰ Sáº´N SÃ€NG!

### Quick Start Command

```bash
./run-locust-interactive.sh
```

### Má»Ÿ Browser

```
http://localhost:8089
```

### Start Testing! ğŸš€

**Good luck vá»›i presentation!** ğŸ€

---

**Last Updated**: 2026-02-10  
**Version**: 1.0  
**Author**: Cloud Computing BTL Team
